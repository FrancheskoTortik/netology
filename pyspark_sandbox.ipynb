{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F, Window as W\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/07/10 12:11:35 WARN Utils: Your hostname, francesco-TravelMate-P238-M resolves to a loopback address: 127.0.1.1; using 192.168.1.129 instead (on interface wlp3s0)\n",
      "22/07/10 12:11:35 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/spark/jars/spark-unsafe_2.12-3.0.3.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "22/07/10 12:11:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+----------+-----------+\n",
      "|iso_code|   location|population|total_cases|\n",
      "+--------+-----------+----------+-----------+\n",
      "|     AFG|Afghanistan|38928341.0|        1.0|\n",
      "|     AFG|Afghanistan|38928341.0|        1.0|\n",
      "|     AFG|Afghanistan|38928341.0|        1.0|\n",
      "+--------+-----------+----------+-----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.format('csv').option('header', 'true').load(\"owid-covid-data.csv\")\n",
    "df.select(\"iso_code\", 'location', 'population', 'total_cases').show(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 72:========================================>             (150 + 4) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------------+---------------+------------------+\n",
      "|iso_code|sum(total_cases)|max(population)|           percent|\n",
      "+--------+----------------+---------------+------------------+\n",
      "|     AND|       1819252.0|        77265.0|23.545615738044393|\n",
      "|     SMR|        638957.0|        33938.0|18.827184866521304|\n",
      "|     MNE|     1.0873903E7|       628062.0|17.313422878633002|\n",
      "|     CZE|    1.69000815E8|     10708982.0|15.781221314967192|\n",
      "|     QAT|     4.4008361E7|      2881060.0|15.275058832513034|\n",
      "|     BHR|     2.5859756E7|      1701583.0|15.197469650319732|\n",
      "|     LUX|       9300282.0|       625976.0|14.857250118215395|\n",
      "|     USA|   4.677925907E9|    331002647.0|14.132593649621176|\n",
      "|     ISR|    1.18035557E8|      8655541.0|13.636993574405112|\n",
      "|     PAN|     5.7985556E7|      4314768.0|13.438858358085533|\n",
      "|     SVN|     2.5270665E7|      2078932.0|12.155599605951517|\n",
      "|     BEL|    1.36567367E8|     11589616.0|11.783597230486325|\n",
      "|     ARM|     3.3388579E7|      2963234.0|11.267614707444636|\n",
      "|     ESP|    4.99412576E8|     46754783.0|10.681529117566432|\n",
      "|     PRT|    1.06706814E8|     10196707.0|10.464830851764201|\n",
      "+--------+----------------+---------------+------------------+\n",
      "only showing top 15 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# df.schema.json()\n",
    "# 15 стран с наибольшим процентом переболевших на 31 марта\n",
    "res_df = df.select(\"iso_code\", 'location', 'population', 'total_cases', 'date')\\\n",
    ".filter(F.col(\"date\") <= '2022-03-31' ).groupBy('iso_code').agg({'population': 'max', 'total_cases' : 'sum'})\n",
    "res_df = res_df.withColumn('percent', F.col(\"sum(total_cases)\") / F.col(\"max(population)\") )\n",
    "res_df.sort('percent', ascending = False).show(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 70:=====================================>                (139 + 5) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------+\n",
      "|iso_code|sum(new_cases)|\n",
      "+--------+--------------+\n",
      "|     BRA|      258385.0|\n",
      "|     IND|      250041.0|\n",
      "|     USA|      240814.0|\n",
      "|     TUR|      138067.0|\n",
      "|     FRA|      135904.0|\n",
      "|     POL|       99992.0|\n",
      "|     ITA|       72446.0|\n",
      "|     DEU|       60719.0|\n",
      "|     ARG|       47432.0|\n",
      "|     UKR|       42502.0|\n",
      "+--------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/07/10 17:28:14 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 11928523 ms exceeds timeout 120000 ms\n",
      "22/07/10 17:28:14 WARN SparkContext: Killing executors is not supported by current scheduler.\n"
     ]
    }
   ],
   "source": [
    "# 10 стран с максимальным зафиксированным кол-вом новых случаев за последнюю неделю марта 2021 в отсортированном порядке по убыванию\n",
    "res_df = df.select(\"iso_code\", 'new_cases', 'date')\\\n",
    ".filter(F.col(\"date\") <= '2021-03-31' )\\\n",
    "    .filter(F.col(\"date\") >= '2021-03-28' )\\\n",
    "        .filter(~F.col('iso_code').like('OWID_%') )\\\n",
    "        .groupBy('iso_code').agg({'new_cases' : 'sum'})\n",
    "# res_df = res_df.withColumn('percent', F.col(\"sum(total_cases)\") / F.col(\"max(population)\") )\n",
    "res_df.sort('sum(new_cases)', ascending = False).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/07/10 23:04:36 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+----------+------+----------+\n",
      "|iso_code|new_cases|      date|    tt|diff_cases|\n",
      "+--------+---------+----------+------+----------+\n",
      "|     RUS|   8979.0|2021-03-28|  null|      null|\n",
      "|     RUS|   8589.0|2021-03-29|8979.0|    -390.0|\n",
      "|     RUS|   8162.0|2021-03-30|8589.0|    -427.0|\n",
      "|     RUS|   8156.0|2021-03-31|8162.0|      -6.0|\n",
      "+--------+---------+----------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res_rus = df.filter(F.col('iso_code') == 'RUS').filter(F.col(\"date\") <= '2021-03-31' )\\\n",
    "    .filter(F.col(\"date\") >= '2021-03-28' ).select(\"iso_code\", 'new_cases', 'date')\n",
    "w = W.orderBy('date')\n",
    "res_rus = res_rus.withColumn('yesterday_cases', F.lag('new_cases', 1).over(w))\n",
    "res_rus.withColumn('diff_cases', F.col('new_cases') - F.col('yesterday_cases') ).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.window.WindowSpec at 0x7f8669803820>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1ec615834a929f8f6354de4f8ec96d7c019114e8d9f7812a39bf7f16da3f4860"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
